{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# On va chercher les données dans le fichier CSV\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "\n",
    "# On va séparer les données en deux parties : les commentaires et les labels\n",
    "X = data['comment_text']\n",
    "y = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# On va séparer les données en deux parties : une pour l'entraînement et une pour le test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# On définit les paramètres, max_words est le nombre de mots maximum que l'on va garder, max_len est la longueur maximale d'un commentaire.\n",
    "max_words = 20000\n",
    "max_len = 150\n",
    "\n",
    "# Ici le tokenizer va transformer les commentaires en séquences de nombres.\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# On va ajouter des 0 pour que toutes les séquences aient la même longueur.\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# On va entraîner un modèle pour chaque label ce qui va nous permettre d'avoir un modèle pour chaque type de commentaire (plus performant que d'avoir un seul modèle pour tous les labels).\n",
    "for label in y.columns:\n",
    "    print(f\"Training model for {label}\")\n",
    "\n",
    "    # On va utiliser un RandomUnderSampler pour équilibrer les classes, càd que l'on va supprimer des exemples de la classe majoritaire (0) pour qu'il y ait autant d'exemples dans la classe minoritaire (1).\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train_pad, y_train[label])\n",
    "\n",
    "    # On crée un modèle avec une couche d'embedding, une couche de LSTM et une couche dense.\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 100, input_length=max_len))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # On compile le modèle avec une loss binary_crossentropy, un optimizer adam et une métrique accuracy.\n",
    "    # On utilise binary_crossentropy car on a un problème de classification binaire, en gros on veut prédire si un commentaire est toxique ou non.\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    history = model.fit(X_resampled, y_resampled, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "    y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "    report = classification_report(y_test[label], y_pred, labels=[0, 1])\n",
    "    print(report)\n",
    "\n",
    "    # On va afficher la matrice de confusion pour chaque label.\n",
    "    cm = confusion_matrix(y_test[label], y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    # En plus, le F1 Score.\n",
    "    f1 = f1_score(y_test[label], y_pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'Confusion Matrix for {label}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
